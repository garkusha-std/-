{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Система распознавания на Scikit-learn\n", "\n", "Готовый практический прототип для курсовой: загрузка данных, предобработка, обучение **Logistic Regression**, **SVM (RBF)** и **Random Forest** через `GridSearchCV`, оценка метрик и визуализации матриц ошибок. \n", "\n", "**Как запускать:**\n", "1. Запустите все ячейки сверху вниз.\n", "2. По умолчанию используется `sklearn.datasets.load_digits` (8x8). Для MNIST (28x28) включите флаг `USE_MNIST = True` в секции ниже.\n", "3. Результаты (отчёты, матрицы ошибок) появятся в конце, лучшие модели сохраняются в `artifacts/`.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Библиотеки\n", "import os, json, time\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from pathlib import Path\n", "from sklearn.datasets import load_digits\n", "from sklearn.model_selection import train_test_split, GridSearchCV\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import SVC\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n", "import joblib\n", "\n", "SEED = 42\n", "np.random.seed(SEED)\n", "\n", "# Папки для артефактов\n", "ART_DIR = Path('artifacts'); ART_DIR.mkdir(exist_ok=True)\n", "\n", "# Можно переключить на полноразмерный MNIST, если среда его предоставляет\n", "USE_MNIST = False  # True -> использовать keras.datasets.mnist\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Загрузка данных\n", "if USE_MNIST:\n", "    try:\n", "        from tensorflow.keras.datasets import mnist\n", "        (X_train_raw, y_train), (X_test_raw, y_test) = mnist.load_data()\n", "        # Нормализация [0,1] и сплющивание 28x28 -> 784\n", "        X_train = (X_train_raw.reshape((X_train_raw.shape[0], -1)).astype('float32')) / 255.0\n", "        X_test  = (X_test_raw.reshape((X_test_raw.shape[0], -1)).astype('float32')) / 255.0\n", "        print('MNIST loaded:', X_train.shape, X_test.shape)\n", "    except Exception as e:\n", "        print('Не удалось загрузить MNIST через keras, используем sklearn digits. Ошибка:', e)\n", "        data = load_digits()\n", "        X = data.data.astype('float32') / 16.0\n", "        y = data.target\n", "        X_train, X_test, y_train, y_test = train_test_split(\n", "            X, y, test_size=0.2, random_state=SEED, stratify=y\n", "        )\n", "else:\n", "    data = load_digits()\n", "    X = data.data.astype('float32') / 16.0\n", "    y = data.target\n", "    X_train, X_test, y_train, y_test = train_test_split(\n", "        X, y, test_size=0.2, random_state=SEED, stratify=y\n", "    )\n", "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Визуализация примеров\n", "def show_examples(X_like, y_like, n=10, title='Примеры изображений'):\n", "    side = int(np.sqrt(X_like.shape[1])) if X_like.ndim == 2 else X_like.shape[1]\n", "    plt.figure(figsize=(10, 2))\n", "    for i in range(n):\n", "        plt.subplot(1, n, i+1)\n", "        if X_like.ndim == 2:\n", "            plt.imshow(X_like[i].reshape(side, side), cmap='gray')\n", "        else:\n", "            plt.imshow(X_like[i], cmap='gray')\n", "        plt.title(int(y_like[i]))\n", "        plt.axis('off')\n", "    plt.suptitle(title)\n", "    plt.show()\n", "\n", "if not USE_MNIST:\n", "    show_examples(data.images.reshape(len(data.images), -1), y[:10], n=10, title='Digits: примеры')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Модели + гиперпараметры\n", "pipelines = {\n", "    'LogReg': Pipeline([\n", "        ('scaler', StandardScaler()),\n", "        ('clf', LogisticRegression(max_iter=10000, solver='liblinear', random_state=SEED))\n", "    ]),\n", "    'SVM_RBF': Pipeline([\n", "        ('scaler', StandardScaler()),\n", "        ('clf', SVC(probability=True, random_state=SEED))\n", "    ]),\n", "    'RF': Pipeline([\n", "        ('clf', RandomForestClassifier(random_state=SEED))\n", "    ])\n", "}\n", "\n", "param_grids = {\n", "    'LogReg': {\n", "        'clf__C': [0.1, 1, 10]\n", "    },\n", "    'SVM_RBF': {\n", "        'clf__C': [0.1, 1, 10],\n", "        'clf__gamma': [0.001, 0.01, 0.1]\n", "    },\n", "    'RF': {\n", "        'clf__n_estimators': [100, 200],\n", "        'clf__max_depth': [None, 10, 20]\n", "    }\n", "}\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Обучение с GridSearchCV\n", "results = {}\n", "for name, pipe in pipelines.items():\n", "    print(f\"\\n=== Обучение {name} ===\")\n", "    grid = GridSearchCV(\n", "        estimator=pipe,\n", "        param_grid=param_grids[name],\n", "        cv=5,\n", "        scoring='accuracy',\n", "        n_jobs=-1,\n", "        verbose=1\n", "    )\n", "    grid.fit(X_train, y_train)\n", "    best = grid.best_estimator_\n", "    y_pred = best.predict(X_test)\n", "    acc = accuracy_score(y_test, y_pred)\n", "    print('Лучшая конфигурация:', grid.best_params_)\n", "    print('CV accuracy:', round(grid.best_score_, 4))\n", "    print('Test accuracy:', round(acc, 4))\n", "    \n", "    # Отчёт и матрица ошибок\n", "    report = classification_report(y_test, y_pred, output_dict=False)\n", "    print(report)\n", "    cm = confusion_matrix(y_test, y_pred)\n", "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "    disp.plot(cmap='Blues')\n", "    plt.title(f'Матрица ошибок: {name}')\n", "    plt.show()\n", "    \n", "    # Сохраняем модель и артефакты\n", "    joblib.dump(best, ART_DIR / f'best_{name}.joblib')\n", "    np.savetxt(ART_DIR / f'cm_{name}.csv', cm, fmt='%d', delimiter=',')\n", "    results[name] = {\n", "        'best_params': grid.best_params_,\n", "        'cv_accuracy': float(grid.best_score_),\n", "        'test_accuracy': float(acc)\n", "    }\n", "\n", "with open(ART_DIR / 'summary.json', 'w', encoding='utf-8') as f:\n", "    json.dump(results, f, ensure_ascii=False, indent=2)\n", "print(\"\\nСводка:\", json.dumps(results, ensure_ascii=False, indent=2))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Итоги\n", "- Сравнили **Logistic Regression**, **SVM (RBF)** и **Random Forest** с кросс-валидацией и перебором гиперпараметров.\n", "- Сохранили лучшие модели и матрицы ошибок в `artifacts/`.\n", "- Для переноса на другой набор (MNIST) выставьте `USE_MNIST=True` (если доступен `keras.datasets`).\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}